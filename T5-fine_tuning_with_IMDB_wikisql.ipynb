{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eea1eae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul 12 14:57:41 2023       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 520.61.05    Driver Version: 520.61.05    CUDA Version: 11.8     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:B3:00.0 Off |                    0 |\r\n",
      "| N/A   31C    P0    55W / 300W |   6431MiB / 32768MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0   N/A  N/A     19021      C   ...azd/miniconda3/bin/python     1354MiB |\r\n",
      "|    0   N/A  N/A     23353      C   ...azd/miniconda3/bin/python     1344MiB |\r\n",
      "|    0   N/A  N/A     58492      C   ...azd/miniconda3/bin/python     2386MiB |\r\n",
      "|    0   N/A  N/A     78268      C   ...azd/miniconda3/bin/python     1344MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5881ed6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading module for CUDA 11.4.4\r",
      "\r\n",
      "CUDA 11.4.4 is now loaded\r",
      "\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71c55695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45abbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f49ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e41aed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip -q datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e82c105a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.t5.modeling_t5 because of the following error (look up to see its traceback):\n[Errno 13] Permission denied: '/cbrc/software/libcudart.so'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py:1091\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1091\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/models/t5/modeling_t5.py:37\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_outputs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     31\u001b[0m     BaseModelOutput,\n\u001b[1;32m     32\u001b[0m     BaseModelOutputWithPastAndCrossAttentions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     Seq2SeqQuestionAnsweringModelOutput,\n\u001b[1;32m     36\u001b[0m )\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedModel\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ALL_LAYERNORM_LAYERS, find_pruneable_heads_and_indices, prune_linear_layer\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/modeling_utils.py:38\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[0;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeepspeed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepspeed_config, is_deepspeed_zero3_enabled\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamic_module_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m custom_object_save\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/deepspeed.py:37\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_accelerate_available() \u001b[38;5;129;01mand\u001b[39;00m is_deepspeed_available():\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeepspeed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HfDeepSpeedConfig \u001b[38;5;28;01mas\u001b[39;00m DeepSpeedConfig\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Inherits from a dummy `object` if accelerate is not available, so that python succeeds to import this file.\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# Deepspeed glue code will never inherit this dummy object as it checks if accelerate is available.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/accelerate/__init__.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.21.0.dev0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maccelerator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbig_modeling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     cpu_offload,\n\u001b[1;32m      6\u001b[0m     cpu_offload_with_hook,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     load_checkpoint_and_dispatch,\n\u001b[1;32m     12\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/accelerate/accelerator.py:35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mhooks\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcheckpointing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_accelerator_state, load_custom_state, save_accelerator_state, save_custom_state\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_loader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoaderDispatcher, prepare_data_loader, skip_first_batches\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/accelerate/checkpointing.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcuda\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mamp\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradScaler\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     25\u001b[0m     MODEL_NAME,\n\u001b[1;32m     26\u001b[0m     OPTIMIZER_NAME,\n\u001b[1;32m     27\u001b[0m     RNG_STATE_NAME,\n\u001b[1;32m     28\u001b[0m     SCALER_NAME,\n\u001b[1;32m     29\u001b[0m     SCHEDULER_NAME,\n\u001b[1;32m     30\u001b[0m     get_pretty_name,\n\u001b[1;32m     31\u001b[0m     is_tpu_available,\n\u001b[1;32m     32\u001b[0m     is_xpu_available,\n\u001b[1;32m     33\u001b[0m     save,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_tpu_available(check_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/accelerate/utils/__init__.py:130\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeepspeed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    122\u001b[0m         DeepSpeedEngineWrapper,\n\u001b[1;32m    123\u001b[0m         DeepSpeedOptimizerWrapper,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    127\u001b[0m         HfDeepSpeedConfig,\n\u001b[1;32m    128\u001b[0m     )\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbnb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m has_4bit_bnb_layers, load_and_quantize_model\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfsdp_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_fsdp_model, load_fsdp_optimizer, save_fsdp_model, save_fsdp_optimizer\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/accelerate/utils/bnb.py:35\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bnb_available():\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbnb\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deepcopy\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bitsandbytes-0.40.0.post4-py3.9.egg/bitsandbytes/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cuda_setup, utils, research\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     MatmulLtState,\n\u001b[1;32m      9\u001b[0m     bmm_cublas,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     13\u001b[0m     matmul_4bit\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bitsandbytes-0.40.0.post4-py3.9.egg/bitsandbytes/research/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m nn\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautograd\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      3\u001b[0m     switchback_bnb,\n\u001b[1;32m      4\u001b[0m     matmul_fp8_global,\n\u001b[1;32m      5\u001b[0m     matmul_fp8_mixed,\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bitsandbytes-0.40.0.post4-py3.9.egg/bitsandbytes/research/nn/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodules\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearFP8Mixed, LinearFP8Global\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bitsandbytes-0.40.0.post4-py3.9.egg/bitsandbytes/research/nn/modules.py:8\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbnb\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GlobalOptimManager\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OutlierTracer, find_outlier_dims\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bitsandbytes-0.40.0.post4-py3.9.egg/bitsandbytes/optim/__init__.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Copyright (c) Facebook, Inc. and its affiliates.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# This source code is licensed under the MIT license found in the\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcextension\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COMPILED_WITH_CUDA\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madagrad\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Adagrad, Adagrad8bit, Adagrad32bit\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bitsandbytes-0.40.0.post4-py3.9.egg/bitsandbytes/cextension.py:13\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m setup\u001b[38;5;241m.\u001b[39minitialized \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m---> 13\u001b[0m     \u001b[43msetup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_cuda_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m lib \u001b[38;5;241m=\u001b[39m setup\u001b[38;5;241m.\u001b[39mlib\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bitsandbytes-0.40.0.post4-py3.9.egg/bitsandbytes/cuda_setup/main.py:105\u001b[0m, in \u001b[0;36mCUDASetup.run_cuda_setup\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda_setup_log \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 105\u001b[0m binary_name, cudart_path, cuda, cc, cuda_version_string \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_cuda_setup\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcudart_path \u001b[38;5;241m=\u001b[39m cudart_path\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bitsandbytes-0.40.0.post4-py3.9.egg/bitsandbytes/cuda_setup/main.py:386\u001b[0m, in \u001b[0;36mevaluate_cuda_setup\u001b[0;34m()\u001b[0m\n\u001b[1;32m    385\u001b[0m cuda_setup \u001b[38;5;241m=\u001b[39m CUDASetup\u001b[38;5;241m.\u001b[39mget_instance()\n\u001b[0;32m--> 386\u001b[0m cudart_path \u001b[38;5;241m=\u001b[39m \u001b[43mdetermine_cuda_runtime_lib_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m cuda \u001b[38;5;241m=\u001b[39m get_cuda_lib_handle()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bitsandbytes-0.40.0.post4-py3.9.egg/bitsandbytes/cuda_setup/main.py:271\u001b[0m, in \u001b[0;36mdetermine_cuda_runtime_lib_path\u001b[0;34m()\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m env_var, value \u001b[38;5;129;01min\u001b[39;00m remaining_candidate_env_vars\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 271\u001b[0m     cuda_runtime_libs\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mfind_cuda_lib_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(cuda_runtime_libs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bitsandbytes-0.40.0.post4-py3.9.egg/bitsandbytes/cuda_setup/main.py:211\u001b[0m, in \u001b[0;36mfind_cuda_lib_in\u001b[0;34m(paths_list_candidate)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_cuda_lib_in\u001b[39m(paths_list_candidate: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Set[Path]:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_cuda_runtime_lib_paths\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolve_paths_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpaths_list_candidate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/bitsandbytes-0.40.0.post4-py3.9.egg/bitsandbytes/cuda_setup/main.py:197\u001b[0m, in \u001b[0;36mget_cuda_runtime_lib_paths\u001b[0;34m(candidate_paths)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m candidate_paths:\n\u001b[0;32m--> 197\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlibname\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    198\u001b[0m         paths\u001b[38;5;241m.\u001b[39madd(path \u001b[38;5;241m/\u001b[39m libname)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/pathlib.py:1456\u001b[0m, in \u001b[0;36mPath.is_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1455\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m S_ISREG(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mst_mode)\n\u001b[1;32m   1457\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/pathlib.py:1232\u001b[0m, in \u001b[0;36mPath.stat\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;124;03mReturn the result of the stat() system call on this path, like\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;124;03mos.stat() does.\u001b[39;00m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/cbrc/software/libcudart.so'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mt5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoTokenizer, T5ForConditionalGeneration\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1055\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py:1082\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m   1081\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module[name])\n\u001b[0;32m-> 1082\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1084\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py:1081\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1079\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m-> 1081\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py:1093\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m   1091\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1093\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1094\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1095\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1096\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to import transformers.models.t5.modeling_t5 because of the following error (look up to see its traceback):\n[Errno 13] Permission denied: '/cbrc/software/libcudart.so'"
     ]
    }
   ],
   "source": [
    "model_name = \"t5-small\"\n",
    "from transformers import AutoTokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d0d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4ba10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c10ed9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import Dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7083684",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('Training_set_IMDB/training_set_sample_no_target.csv')\n",
    "df1 = df1.dropna()\n",
    "\n",
    "\n",
    "shuffled_df = df1.sample(frac=1, random_state=42)  # Set random_state for reproducibility\n",
    "\n",
    "train_df, eval_df = train_test_split(shuffled_df, test_size=0.1, random_state=42)\n",
    "\n",
    "# 'train_df' will contain 80% of the shuffled data for training\n",
    "# 'eval_df' will contain 20% of the shuffled data for evaluation\n",
    "\n",
    "\n",
    "text = []\n",
    "sql = []\n",
    "\n",
    "for index, row in train_df.iterrows():\n",
    "    \n",
    "    text_input = \"Translate to SQL: \" + row['Text'],\n",
    "    sql_input = row['SQL']\n",
    "    text.append(text_input)\n",
    "    sql.append(sql_input)\n",
    "    \n",
    "inputs = {\"inputs\": text,\n",
    "        \"target\": sql}\n",
    "\n",
    "train_dataset = Dataset.from_dict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc786cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_2 = []\n",
    "sql_2 = []\n",
    "\n",
    "for index, row in eval_df.iterrows():\n",
    "    \n",
    "    text_input = \"Translate to SQL: \" + row['Text'],\n",
    "    sql_input = row['SQL']\n",
    "    text_2.append(text_input)\n",
    "    sql_2.append(sql_input)\n",
    "    \n",
    "inputs_2 = {\"inputs\": text_2,\n",
    "        \"target\": sql_2}\n",
    "eval_dataset = Dataset.from_dict(inputs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24fc70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_lenght(x):\n",
    "    x[\"input_len\"] = len(tokenizer(x[\"inputs\"]).input_ids)\n",
    "    x[\"input_longer_256\"] = int(x[\"input_len\"]>256)\n",
    "    x[\"input_longer_128\"] = int(x[\"input_len\"]>128)\n",
    "    x[\"input_longet_64\"] = int(x[\"input_len\"]>64)\n",
    "    x[\"output_len\"] = len(tokenizer(x[\"target\"]).input_ids)\n",
    "    x[\"output_longet_256\"] = int(x[\"output_len\"]>256)\n",
    "    x[\"output_longet_128\"] = int(x[\"output_len\"]>128)\n",
    "    x[\"output_longet_64\"] = int(x[\"output_len\"]>64)\n",
    "    return x\n",
    "\n",
    "sample_size = 10000\n",
    "data_stats = train_dataset.select(range(sample_size)).map(map_to_lenght, num_proc=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d76548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_and_print(x):\n",
    "    if len(x[\"input_len\"])==sample_size:\n",
    "        print(\n",
    "            f\"Input mean: {sum(x['input_len'])/sample_size} \\n % of input len > 256: {sum(x['input_longer_256'])/sample_size}, \\n % of input len > 128: {sum(x['input_longer_128'])/sample_size}, \\n % of input len > 64: {sum(x['input_longet_64'])/sample_size}, \\n Ouput mean: {sum(x['output_len'])/sample_size},\\n% of output len > 256: {sum(x['output_longet_256'])/sample_size}, \\n% of output len > 128: {sum(x['output_longet_128'])/sample_size}, \\n% of output len > 64: {sum(x['output_longet_64'])/sample_size}\")\n",
    "\n",
    "output = data_stats.map(compute_and_print, batched=True, batch_size=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96d88e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_features(example_batch, padding = \"max_length\"):\n",
    "    inputs = tokenizer.batch_encode_plus(example_batch[\"inputs\"],is_split_into_words=True, max_length=64, truncation=True)\n",
    "    \n",
    "    targets = tokenizer.batch_encode_plus(example_batch[\"target\"], max_length=256,truncation = True)\n",
    "    if padding == \"max_length\":\n",
    "        targets[\"inputs_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in target] for target in targets[\"input_ids\"]\n",
    "        ]\n",
    "    \n",
    "    inputs[\"labels\"] = targets['input_ids']\n",
    "    return inputs\n",
    "\n",
    "train_data = train_dataset.map(convert_to_features, batched=True, remove_columns=train_dataset.column_names)\n",
    "test_data = eval_dataset.map(convert_to_features, batched=True, remove_columns=eval_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35546b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd753dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['input_ids', 'attention_mask', 'labels']\n",
    "\n",
    "train_data.set_format(type='torch', columns=columns)\n",
    "test_data.set_format(type='torch', columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9cfd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375cbb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "import os\n",
    "\n",
    "output_dir = 'T5-fine-tuned-with-IMDB-wikisql'\n",
    "os.mkdir(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9a87fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    per_device_eval_batch_size=16,\n",
    "    predict_with_generate=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    do_train=True,\n",
    "    learning_rate=2e-4,\n",
    "    weight_decay=0.1,\n",
    "    do_eval=True,\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    overwrite_output_dir=True,\n",
    "    save_total_limit=3,\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    fp16=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d29d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q rouge_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84447030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluate import load\n",
    "rouge = load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570e9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as n\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    predictions, labels = pred\n",
    "    \n",
    "    pred_str = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels[labels== -101] = tokenizer.pad_token_id\n",
    "    label_str = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    rouge_output = rouge.compute(predictions=pred_str, references=label_str, rouge_types=[\"rouge2\"])[\"rouge2\"].mid\n",
    "    return {\n",
    "        \"rouge2 precision\": round(rouge_output.precision, 4),\n",
    "        \"rouge2 recall\": round(rouge_output.recall, 4),\n",
    "        \"rouge2 F1 score\": round(rouge_output.fmeasure, 4)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194641d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c836f916",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model = model,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset= test_data,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64966203",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e7ff2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e1de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283bcf14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0fcce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
